{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient\n",
    "from azure.ai.formrecognizer import DocumentAnalysisClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SimpleField,\n",
    "    SearchFieldDataType,\n",
    "    SearchableField,\n",
    "    SearchField,\n",
    "    VectorSearch,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    VectorSearchProfile,\n",
    "    SemanticConfiguration,\n",
    "    SemanticPrioritizedFields,\n",
    "    SemanticField,\n",
    "    SemanticSearch,\n",
    "    SearchIndex,\n",
    ")\n",
    "from azure.search.documents.models import VectorizedQuery\n",
    "from openai import AzureOpenAI\n",
    "import os\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "load_dotenv()  # Load variables from .env file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload to blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_blob_client():\n",
    "    connection_string = str(os.getenv(\"BLOB_CONNECTION_STRING\"))\n",
    "    return BlobServiceClient.from_connection_string(connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_blob_container_client(container_name, blob_service_client):\n",
    "    # get the container client\n",
    "    return blob_service_client.get_container_client(container_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_blob_containers():\n",
    "    blob_service_client = get_blob_client()\n",
    "    # List all containers in the storage account\n",
    "    containers = blob_service_client.list_containers()\n",
    "    for container in containers:\n",
    "        print(container['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docs\n"
     ]
    }
   ],
   "source": [
    "list_blob_containers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blob_upload(local_file_path):\n",
    "    # get the blob client\n",
    "    blob_service_client = get_blob_client()\n",
    "    # set container name\n",
    "    container_name = \"docs\"\n",
    "    # get the container client\n",
    "    container_client = get_blob_container_client(container_name=container_name,blob_service_client=blob_service_client)\n",
    "    # local_file_path = \"docs/test_ima_1.pdf\"\n",
    "    #get the filename\n",
    "    blob_name = os.path.basename(local_file_path)\n",
    "    # uplaod\n",
    "    with open(local_file_path, \"rb\") as data:\n",
    "        container_client.upload_blob(name=blob_name, data=data, overwrite=True)\n",
    "\n",
    "    print(f\"Uploaded {blob_name} to {container_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download File from blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the blob to a local file\n",
    "def blob_download(filename):\n",
    "    # get the blob client\n",
    "    blob_service_client = get_blob_client()\n",
    "    # get the container client\n",
    "    container_client = get_blob_container_client(container_name=container_name,blob_service_client=blob_service_client)\n",
    "    with open(f\"downloads/{filename}\", \"wb\") as download_file:\n",
    "        download_blob = container_client.download_blob(filename)\n",
    "        download_blob.readinto(download_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_download('test_ima.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Document Intelligence to get text from PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_intelligence_client():\n",
    "    endpoint = str(os.getenv(\"DOC_INT_ENDPOINT\"))\n",
    "    key = str(os.getenv(\"DOC_INT_KEY\"))\n",
    "    return DocumentAnalysisClient(\n",
    "        endpoint=endpoint, credential=AzureKeyCredential(key)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_document_text(local_path):\n",
    "    document_analysis_client = get_document_intelligence_client()\n",
    "    with open(local_path, \"rb\") as f:\n",
    "        poller = document_analysis_client.begin_analyze_document(\n",
    "            \"prebuilt-document\", document=f\n",
    "        )\n",
    "    result = poller.result()\n",
    "\n",
    "    document_text = \"\"\n",
    "    for page in result.pages:\n",
    "        for line in page.lines:\n",
    "            document_text += line.content + \"\\n\"\n",
    "\n",
    "    return document_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract_document_text('docs/test_ima.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding the text using ada-002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_model_client():\n",
    "    # Azure OpenAI credentials\n",
    "    ada_endpoint = str(os.getenv(\"ADA_ENDPOINT\"))\n",
    "    ada_key = str(os.getenv(\"ADA_KEY\"))\n",
    "    # Initialize Azure OpenAI client\n",
    "    return AzureOpenAI(\n",
    "        azure_endpoint=ada_endpoint,\n",
    "        api_key=ada_key,\n",
    "        api_version=\"2023-05-15\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(text, max_tokens=8191):\n",
    "    ada_deployment = \"text-embedding-ada-002\"\n",
    "    \n",
    "    # Split the text into chunks if it exceeds the max token limit\n",
    "    chunks = [text[i:i+max_tokens] for i in range(0, len(text), max_tokens)]\n",
    "    openai_client = get_embedding_model_client()\n",
    "    embeddings = []\n",
    "    for chunk in chunks:\n",
    "        response = openai_client.embeddings.create(\n",
    "            input=chunk,\n",
    "            model=ada_deployment\n",
    "        )\n",
    "        embedding = response.data[0].embedding\n",
    "        embeddings.append(embedding)\n",
    "    \n",
    "    # If there are multiple chunks, average the embeddings\n",
    "    if len(embeddings) > 1:\n",
    "        return np.mean(embeddings, axis=0).tolist()\n",
    "    else:\n",
    "        return embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimension: 1536\n",
      "First few values of the embedding: [-0.011320868002561232, -0.02466426727672418, -0.008200732214997212, -0.042265833665927253, -0.030091070259610813]\n"
     ]
    }
   ],
   "source": [
    "# Create embeddings\n",
    "embeddings = create_embeddings(extract_document_text(\"docs/test_ima_1.pdf\"))\n",
    "\n",
    "print(f\"Embedding dimension: {len(embeddings)}\")\n",
    "print(f\"First few values of the embedding: {embeddings[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AI Search/Cognitive Search : Create an Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ai_search_index_client():\n",
    "    admin_key = str(os.getenv(\"AI_SEARCH_KEY\"))\n",
    "    endpoint = str(os.getenv(\"AI_SEARCH_ENDPOINT\"))\n",
    "    if not admin_key or not endpoint:\n",
    "        raise ValueError(\"AI_SEARCH_KEY or AI_SEARCH_ENDPOINT environment variables are not set\")\n",
    "    \n",
    "    print(f\"Connecting to: {endpoint}\")\n",
    "    try:\n",
    "        return SearchIndexClient(endpoint=endpoint, credential=AzureKeyCredential(admin_key))\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating SearchIndexClient: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector_index(index_name):\n",
    "    index_client = get_ai_search_index_client()\n",
    "    # predefined and cant change for ada-002\n",
    "    ada_embedding_dimensions =1536\n",
    "    # Define the index schema\n",
    "    fields = [\n",
    "        SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True, sortable=True, filterable=True, facetable=True),\n",
    "        SearchableField(name=\"title\", type=SearchFieldDataType.String),\n",
    "        SearchableField(name=\"content\", type=SearchFieldDataType.String),\n",
    "        SearchableField(name=\"category\", type=SearchFieldDataType.String,\n",
    "                        filterable=True),\n",
    "        SearchField(name=\"titleVector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "                    searchable=True, vector_search_dimensions=ada_embedding_dimensions,vector_search_profile_name=\"myHnswProfile\"),\n",
    "        SearchField(name=\"contentVector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "                    searchable=True, vector_search_dimensions=ada_embedding_dimensions,vector_search_profile_name=\"myHnswProfile\"),\n",
    "    ]\n",
    "    # Configure the vector search configuration  \n",
    "    vector_search = VectorSearch(\n",
    "        algorithms=[\n",
    "            HnswAlgorithmConfiguration(\n",
    "                name=\"myHnsw\"\n",
    "            )\n",
    "        ],\n",
    "        profiles=[\n",
    "            VectorSearchProfile(\n",
    "                name=\"myHnswProfile\",\n",
    "                algorithm_configuration_name=\"myHnsw\",\n",
    "                # vectorizer=\"myVectorizer\"\n",
    "            )\n",
    "        ],\n",
    "        # vectorizers=[\n",
    "        #     AzureOpenAIVectorizer(\n",
    "        #         name=\"myVectorizer\",\n",
    "        #         azure_open_ai_parameters=AzureOpenAIParameters(\n",
    "        #             resource_uri=ada_endpoint,\n",
    "        #             deployment_id=ada_deployment,\n",
    "        #             model_name=ada_deployment,\n",
    "        #             api_key=ada_key\n",
    "        #         )\n",
    "        #     )\n",
    "        # ]\n",
    "    )\n",
    "    \n",
    "    semantic_config = SemanticConfiguration(\n",
    "        name=\"my-semantic-config\",\n",
    "        prioritized_fields=SemanticPrioritizedFields(\n",
    "            title_field=SemanticField(field_name=\"title\"),\n",
    "            keywords_fields=[SemanticField(field_name=\"category\")],\n",
    "            content_fields=[SemanticField(field_name=\"content\")]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Create the semantic settings with the configuration\n",
    "    semantic_search = SemanticSearch(configurations=[semantic_config])\n",
    "\n",
    "    # Create the search index with the semantic settings\n",
    "    index = SearchIndex(name=index_name, fields=fields,\n",
    "                        vector_search=vector_search, semantic_search=semantic_search)\n",
    "    result = index_client.create_or_update_index(index)\n",
    "    print(f'{result.name} created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to: https://aisearchpoc0924.search.windows.net\n",
      "legal-docs created\n"
     ]
    }
   ],
   "source": [
    "create_vector_index(\"legal-docs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AI Search/Cognitive Search : Uploading to an index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ai_search_client():\n",
    "    # Initialize Search client\n",
    "    admin_key = str(os.getenv(\"AI_SEARCH_KEY\"))\n",
    "    endpoint = str(os.getenv(\"AI_SEARCH_ENDPOINT\"))\n",
    "    index_name = 'legal-docs'\n",
    "    return SearchClient(endpoint=endpoint, index_name=index_name, credential=AzureKeyCredential(admin_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_to_vector_index(documents):\n",
    "    search_client = get_ai_search_client()\n",
    "    # Upload documents to the index\n",
    "    result = search_client.upload_documents(documents)\n",
    "    print(f\"Uploaded {len(result)} documSents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare and index your documents\n",
    "document_text1 = extract_document_text(local_path=\"docs/test_ima.pdf\")\n",
    "document_text2 = extract_document_text(local_path=\"docs/test_ima_1.pdf\")\n",
    "documents = [\n",
    "    {\n",
    "        \"id\": \"1\",\n",
    "        \"title\": \"Sample IMA 1\",\n",
    "        \"content\": document_text1,\n",
    "        \"category\": \"IMA\",\n",
    "        \"titleVector\": create_embeddings(\"Sample IMA 1\"),\n",
    "        \"contentVector\": create_embeddings(document_text1)\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"2\",\n",
    "        \"title\": \"Sample IMA 2\",\n",
    "        \"content\": document_text2,\n",
    "        \"category\": \"IMA\",\n",
    "        \"titleVector\": create_embeddings(\"Sample IMA 2\"),\n",
    "        \"contentVector\": create_embeddings(document_text2)\n",
    "    }\n",
    "    # Add more documents as needed\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 2 documSents\n"
     ]
    }
   ],
   "source": [
    "upload_to_vector_index(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AI Search/Cognitive Search : Searching an index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_vector_index(query):\n",
    "    embedding  = create_embeddings(query)\n",
    "    vector_query = VectorizedQuery(vector=embedding, k_nearest_neighbors=3, fields=\"titleVector\")\n",
    "    search_client = get_ai_search_client()\n",
    "    #perform vector search\n",
    "    return search_client.search(  \n",
    "        search_text=query,  \n",
    "        vector_queries= [vector_query],\n",
    "        select=[\"title\", \"content\", \"category\"],\n",
    "    )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['content', 'title', 'category', '@search.score', '@search.reranker_score', '@search.highlights', '@search.captions'])\n",
      "Title: Sample IMA 1\n",
      "Score: 0.03306011110544205\n",
      "Category: IMA\n",
      "\n",
      "dict_keys(['content', 'title', 'category', '@search.score', '@search.reranker_score', '@search.highlights', '@search.captions'])\n",
      "Title: Sample IMA 2\n",
      "Score: 0.03306011110544205\n",
      "Category: IMA\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = search_vector_index(\"authorized person\")\n",
    "for result in results:  \n",
    "    print(result.keys())\n",
    "    print(f\"Title: {result['title']}\")  \n",
    "    print(f\"Score: {result['@search.score']}\")  \n",
    "    #print(f\"Content: {result['content']}\")  \n",
    "    print(f\"Category: {result['category']}\\n\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_context(query):\n",
    "    # Perform vector search\n",
    "    results = search_vector_index(query)\n",
    "    # Extract and return relevant context as JSON objects\n",
    "    context = [\n",
    "        {\n",
    "            \"title\": result['title'],\n",
    "            \"category\": result['category'],\n",
    "            \"content\": result['content']\n",
    "        } for result in results\n",
    "    ]\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gpt4o_client():\n",
    "    # Azure OpenAI credentials\n",
    "    gpt4o_endpoint = os.getenv(\"GPT4O_ENDPOINT\")\n",
    "    gpt4o_key = os.getenv(\"GPT4O_KEY\")\n",
    "    deployment_name = \"gpt-4o\"\n",
    "    \n",
    "    # Initialize Azure OpenAI client\n",
    "    client = AzureOpenAI(\n",
    "        api_key=gpt4o_key,\n",
    "        api_version=\"2023-05-15\",\n",
    "        azure_endpoint=gpt4o_endpoint\n",
    "    )\n",
    "    \n",
    "    return client, deployment_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(query, context):\n",
    "    context_str = json.dumps(context, indent=2)\n",
    "    prompt = f\"\"\"Use the following information to answer the user's question. \n",
    "    If the information doesn't contain the answer, say you don't know.\n",
    "\n",
    "    Context (JSON format):\n",
    "    {context_str}\n",
    "\n",
    "    User's question: {query}\n",
    "\n",
    "    Provide a concise answer based on the given context. If relevant, mention which document(s) \n",
    "    (by title or category) the information comes from.\n",
    "    \"\"\"\n",
    "    openai_client,deployment_name = get_gpt4o_client()\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=deployment_name,  # Your deployed GPT-4o model name\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"authorized person\"\n",
    "context = get_relevant_context(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An **\"Authorised Person\"** refers to an individual who is designated with authority to give instructions on behalf of the client. This individual's name, details, and signature are specified in the documentation related to the investment management agreement.\n",
      "\n",
      "**In the context of \"Sample IMA 1\"**:\n",
      "The details of the Authorised Person appear in **Schedule 1**, and changes to the list of Authorised Persons can be made by the client by giving notice to the Manager.\n",
      "\n",
      "**In the context of \"Sample IMA 2\"**:\n",
      "Although \"Sample IMA 2\" discusses client instructions and communication, it does not explicitly define an \"Authorised Person\" as outlined in \"Sample IMA 1.\"\n",
      "\n",
      "In summary, for specific details related to an \"Authorised Person,\" refer to **Sample IMA 1**.\n"
     ]
    }
   ],
   "source": [
    "response = generate_response(query,context)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
